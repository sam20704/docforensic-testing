"""
Forensic Document Validation API.

Architecture:
    POST /validate → ForensicValidator → PipelineResult → JSON

Agents:
    Critic  (Llama 3.2) → audits evidence + detects false positives
    Judge   (Claude)     → final verdict, CAN override rules
"""

import logging
import time
from contextlib import asynccontextmanager

from fastapi import FastAPI, Request
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse

from app.config import settings
from app.schemas.evidence import EvidenceCaseFile
from app.services.validator import validate_case, get_validator, PipelineError
from app.services.llm_clients import shutdown_clients


# ═══════════════════════════════════════════════════════
# LOGGING
# ═══════════════════════════════════════════════════════

logging.basicConfig(
    level=getattr(logging, settings.LOG_LEVEL.upper(), logging.INFO),
    format="%(asctime)s | %(name)-20s | %(levelname)-7s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

logger = logging.getLogger("forensic.api")


# ═══════════════════════════════════════════════════════
# LIFECYCLE
# ═══════════════════════════════════════════════════════

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Startup:  initialize validator + LLM clients
    Shutdown: close all client connections gracefully
    """
    logger.info("═══ Forensic Validation API starting ═══")
    logger.info(f"Critic model:  {settings.LLAMA_MODEL}")
    logger.info(f"Judge model:   {settings.CLAUDE_MODEL}")
    logger.info(f"Max retries:   {settings.MAX_RETRIES}")
    logger.info(f"Log level:     {settings.LOG_LEVEL}")

    get_validator()

    logger.info("═══ API ready ═══")
    yield

    logger.info("═══ Shutting down ═══")
    await shutdown_clients()
    logger.info("═══ Shutdown complete ═══")


# ═══════════════════════════════════════════════════════
# APP
# ═══════════════════════════════════════════════════════

app = FastAPI(
    title="Forensic Document Validation API",
    description=(
        "Adaptive forensic validation pipeline. "
        "Critic agent audits evidence quality and detects false positive patterns. "
        "Judge agent produces final verdict and CAN override rule-based scores "
        "when evidence warrants it."
    ),
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
)


# ═══════════════════════════════════════════════════════
# ERROR RESPONSES
# ═══════════════════════════════════════════════════════

class ErrorResponse:
    """Standardized error response builder."""

    @staticmethod
    def validation_error(detail: str) -> JSONResponse:
        return JSONResponse(
            status_code=422,
            content={
                "success": False,
                "error": "validation_error",
                "detail": detail,
            },
        )

    @staticmethod
    def pipeline_error(case_id: str, stage: str, detail: str) -> JSONResponse:
        return JSONResponse(
            status_code=502,
            content={
                "success": False,
                "error": "pipeline_error",
                "case_id": case_id,
                "failed_stage": stage,
                "detail": detail,
            },
        )

    @staticmethod
    def internal_error(detail: str) -> JSONResponse:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": "internal_error",
                "detail": detail,
            },
        )


# ═══════════════════════════════════════════════════════
# MIDDLEWARE
# ═══════════════════════════════════════════════════════

@app.middleware("http")
async def log_requests(request: Request, call_next):
    """Log every request with timing. No sensitive data."""
    start = time.monotonic()
    response = await call_next(request)
    duration_ms = (time.monotonic() - start) * 1000

    logger.info(
        f"{request.method} {request.url.path} → {response.status_code} "
        f"({duration_ms:.0f}ms)"
    )

    return response


# ═══════════════════════════════════════════════════════
# EXCEPTION HANDLERS
# ═══════════════════════════════════════════════════════

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(
    request: Request,
    exc: RequestValidationError,
):
    """
    Clean Pydantic validation errors.

    Catches:
        - Missing required fields
        - Invalid types
        - Enum mismatches
        - Priority/score alignment failures
    """
    errors = []
    for error in exc.errors():
        loc = " → ".join(str(part) for part in error["loc"])
        errors.append(f"{loc}: {error['msg']}")

    detail = "; ".join(errors)
    logger.warning(f"Validation error: {detail}")

    return ErrorResponse.validation_error(detail)


# ═══════════════════════════════════════════════════════
# ENDPOINTS
# ═══════════════════════════════════════════════════════

@app.get("/health", tags=["System"], summary="Health check")
async def health():
    """
    Returns service status and model configuration.
    """
    return {
        "status": "healthy",
        "version": "2.0.0",
        "models": {
            "critic": settings.LLAMA_MODEL,
            "judge": settings.CLAUDE_MODEL,
        },
    }


@app.post(
    "/validate",
    tags=["Validation"],
    summary="Validate a document case file",
    response_description="Forensic verdict with explanation, evidence, and override tracking",
)
async def validate_document(case: EvidenceCaseFile):
    """
    Run adaptive forensic validation on a deterministic case file.

    **Pipeline:**
    1. Receives module scores + signals from deterministic engine
    2. Critic Agent (Llama 3.2) audits evidence consistency + detects FP patterns
    3. Judge Agent (Claude) produces final verdict — CAN override rules
    4. Stores case for learning (non-blocking, best-effort)

    **Input:**
    - `case_id`: Unique identifier
    - `metadata`: Module result (score 0-10 + signals)
    - `font`: Module result (score 0-10 + signals)
    - `compression`: Module result (score 0-10 + signals)
    - `qr`: Optional module result
    - `deterministic_score`: Pre-computed score (0-10)
    - `priority`: Pre-computed priority (Low/Medium/High)

    **Output:**
    - `verdict`: Judge's final decision (tampered, probability, severity, override info)
    - `critic_report`: Evidence audit (consistency, FP indicators, signal strength)
    - `duration_ms`: Processing time
    - `success`: True/False
    - `similar_cases_used`: Number of past cases used for context

    **Key difference from v1:**
    The Judge CAN override the rule-based score. If rules say High but
    evidence shows a scanner workflow false positive, the Judge will
    downgrade to Low and set `override_applied=true`.

    **Error codes:**
    - `422`: Invalid input (schema violation)
    - `502`: LLM pipeline failure (critic or judge stage)
    - `500`: Unexpected server error
    """
    try:
        result = await validate_case(case)
        return result.to_dict()

    except PipelineError as e:
        logger.error(f"[{e.case_id}] Pipeline failed at {e.stage}: {e.cause}")
        return ErrorResponse.pipeline_error(
            case_id=e.case_id,
            stage=e.stage,
            detail=str(e.cause),
        )

    except Exception as e:
        logger.error(f"Unexpected error: {e}", exc_info=True)
        return ErrorResponse.internal_error(
            detail="An unexpected error occurred. Check server logs.",
        )
